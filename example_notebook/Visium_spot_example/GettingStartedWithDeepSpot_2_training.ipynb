{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403c8d82-26fe-46b3-aa3c-ef8c1d7fde5a",
   "metadata": {},
   "source": [
    "## DeepSpot Training\n",
    "\n",
    "In this second notebook, we will provide the logic and a basic example of how to train DeepSpot on your spatial transcriptomics data. We assume that you have already preprocessed your data and prepared it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288d529-fde9-44fc-a423-c2d4d9478ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8485cfb0-ac33-41e7-851d-50bab930c997",
   "metadata": {},
   "source": [
    "Export packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32fc99-7943-4af7-b23c-847604f477a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspot.utils.utils_image import get_morphology_model_and_preprocess\n",
    "from deepspot.utils.utils import plot_loss_values\n",
    "\n",
    "from deepspot.spot import DeepSpotDataLoader\n",
    "from deepspot.spot import DeepSpot\n",
    "\n",
    "\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from pathlib import Path\n",
    "import lightning as L\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "yaml.Dumper.ignore_aliases = lambda *args : True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8e5a1-c544-4954-8878-4ba171984c9d",
   "metadata": {},
   "source": [
    "Here, we specify the input parameters and the dataloader settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc4cb9-2371-4de2-ac43-8ea8301be6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d32be2-f6ca-4917-8211-6617bb31bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = set(['ZEN38'])\n",
    "out_folder = \"example_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc784680-80a9-40fd-9ef5-da69ccf6bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_param = {\n",
    "# specify the used foundation model \n",
    "# to extract the precomputed tile representations\n",
    "\"morphology_model_name\": \"inception\", \n",
    "\"batch_size\": 1024,\n",
    "# use the spot, subspots, and neighboring spots.\n",
    "'spot_context': 'spot_subspot_neighbors',\n",
    "# the radius used to compute the neighbors around \n",
    "# the central spot based on the array coordinates.\n",
    "'radius_neighbors': 1, \n",
    "# oversampling\n",
    "'resolution': 1,\n",
    "# if to normalize the data during training \n",
    "# and the type of normalization\n",
    "'normalize': 'standard', # None\n",
    "'augmentation': 'default' # to use 'aestetik' -> pip install aestetik;\n",
    "        }\n",
    "batch_size = dataloader_param[\"batch_size\"]\n",
    "image_feature_model = dataloader_param['morphology_model_name']\n",
    "num_workers = max(1, torch.get_num_threads() - 1)\n",
    "\n",
    "del dataloader_param[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45941916-2ee0-43f3-b642-ab1f1cbb21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(f\"{out_folder}/data/info_highly_variable_genes_Visium.csv\")\n",
    "selected_genes_bool = genes.isPredicted.values\n",
    "genes_to_predict = genes[selected_genes_bool]\n",
    "genes_to_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a5881c-bd92-4f1f-990d-f73389e55e08",
   "metadata": {},
   "source": [
    "We need the feature_dim when defining the DeepSpot input dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58aa85-301b-4220-bf48-3013f90ef490",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, feature_dim = get_morphology_model_and_preprocess(model_name=image_feature_model, \n",
    "                                                                                device=device)\n",
    "feature_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde106cf-6161-4792-bf5e-2a41f5fc96d7",
   "metadata": {},
   "source": [
    "Now, we prepare the DeepSpot dataloader. `out_folder` specifies the parent location where the preprocessed data is stored. `genes_to_keep` is a boolean np.array that indicates which genes to include for training and prediction. `samples` refers to the slide_ids, which are used to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aec656-bd25-4aab-b4e1-2b83fd41c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader_custom = DeepSpotDataLoader(\n",
    "                               out_folder=out_folder, \n",
    "                               samples=samples, \n",
    "                               genes_to_keep=selected_genes_bool,\n",
    "                               **dataloader_param\n",
    ")\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset=train_data_loader_custom,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      num_workers=num_workers,\n",
    "                                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29754f4-b3b1-460f-8f93-c9654d0dd7ff",
   "metadata": {},
   "source": [
    "Here, you can customize the hyperparameters of DeepSpot. For this example, we will train it using the default parameters. The `scaler` is important to be the same as the one used during training, so that the predictions of DeepSpot can be rescaled back to their original ranges using the `inverse_transform` function. \n",
    "\n",
    "##### IMPORTANT: Remember to manually rescale the values, as this is not done automatically.\n",
    "```\n",
    "expression_norm = model(X)\n",
    "expression_norm should be np.array\n",
    "expression = model.inverse_transform(expression_norm)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f4bbe-8d49-435b-bb11-7420e32e49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "\n",
    "        }\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c6cf3-cc14-45b1-9e18-2961e0a79612",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DeepSpot(input_size=feature_dim,\n",
    "                output_size=int(selected_genes_bool.sum()),\n",
    "                scaler=train_data_loader_custom.scaler,\n",
    "                **param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978908a5-0641-4c8f-8224-90c8ad9590d2",
   "metadata": {},
   "source": [
    "We train the model with early stoppping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9caae17-a88d-4abf-954d-5bc341a7782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=10, logger=False, enable_checkpointing=False, callbacks=[EarlyStopping(monitor=\"train_step\",\n",
    "                                                                    patience=3,\n",
    "                                                                    min_delta=0.01, \n",
    "                                                                    mode=\"min\")])\n",
    "trainer.fit(regressor, train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479df52e-56da-440a-bac6-e931e3c940bf",
   "metadata": {},
   "source": [
    "We also provide a function to visualize your training loss. Keep in mind that this is only an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046235f-9088-4346-b70e-b5968171474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_values(regressor.training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b87988-b889-4f07-8ce3-d65e37fe3857",
   "metadata": {},
   "source": [
    "Once DeepSpot is trained, you can export its weights and hyperparameters and use them for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1441a6f-6a8e-4cff-8228-1ed334f0ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"pretrained_model_weights/example_model\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05437de-48d4-441c-a181-18e928a1b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'pretrained_model_weights/example_model/weights_Visium.pkl'\n",
    "torch.save(regressor, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26facee3-018a-4667-9361-c1bb64e89369",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparam = dict(regressor.hparams)\n",
    "hparam['image_feature_model'] = dataloader_param['morphology_model_name']\n",
    "hparam['scaler'] = str(hparam['scaler']) # ignore since it is an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb3c9f-96c1-4305-85c7-63d9930f5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the output YAML file path\n",
    "yaml_file_path = 'pretrained_model_weights/example_model/hparam_Visium.yaml'\n",
    "\n",
    "# Save the dictionary as a YAML file\n",
    "with open(yaml_file_path, 'w') as yaml_file:\n",
    "    yaml.dump(hparam, yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74d3c7-8e6a-46d1-9dad-88154e0bcd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba30fc-aa3b-4b81-aef8-9a3844a3e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d3edc-55a3-47fd-80aa-8d102b8c1bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nonchev",
   "language": "python",
   "name": "nonchev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
